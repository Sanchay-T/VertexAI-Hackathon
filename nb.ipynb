{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# turn on wandb logging for langchain\n",
    "os.environ[\"LANGCHAIN_WANDB_TRACING\"] = \"true\"\n",
    "# optionally set your wandb settings or configs\n",
    "os.environ[\"WANDB_PROJECT\"] = \"langchain-tracing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'participant-sa-12-ghc-013.json'\n",
    "\n",
    "from langchain.llms import VertexAI\n",
    "from langchain import PromptTemplate , LLMChain\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = VertexAI(model_name=\"text-bison@001\") # select the model\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "question = \"What is Resume?\"\n",
    "llm_chain.run(question)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'embeddings' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mThis is a test document.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 2\u001b[0m query_result \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39membed_query(text)\n\u001b[0;32m      3\u001b[0m doc_result \u001b[39m=\u001b[39m embeddings\u001b[39m.\u001b[39membed_documents([text])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'embeddings' is not defined"
     ]
    }
   ],
   "source": [
    "text = \"This is a test document.\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "doc_result = embeddings.embed_documents([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content=\"Content design\\nSpeaking\\nContent Marketing\\nDigital Marketing\\nContent editing\\nA l f r e d o\\nT o r r e s\\nEducation\\nWork Experience\\nContact MeAbout me\\nExpertise SkillDigital Marketing\\nLorem Ipsum is simply dummy\\ntext of the printing and\\ntypesetting industry. Lorem Ipsum\\nhas been the industry's standard\\ndummy text ever since the 1500s,\\nwhen an unknown printer took a\\ngalley of type and scrambled it to\\nmake a type specimen book.2015-2017\\nSenior Marketing strategies \\nSenior Marketing strategies 2017-2019School Of Marketing University\\n123 Anywhere st., Any City, \\nST 12345\\nSalford & co. | 2019-2020\\nlliceria & co. | 2020-presetmade more than 1000 deal\\nwith big companies\\ncomplete a lot of complicated\\nwork\\nmade more than 1000 deal\\nwith big companies\\ncomplete a lot of complicated\\nwork\\nEnsured customer\\nsatisfaction by handling day-\\nto-day affairsSchool Of Economics university\\n123 Anywhere st., Any City, \\nST 12345\\n+123-456-7890\\nhello@reallygreatsite.com\\nwww.reallygreatsite.com\\n123 Anywhere st., Any City, \\nST 12345\", metadata={'source': 'pdf/_Professional CV Resume.pdf', 'page': 0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"pdf/_Professional CV Resume.pdf\")\n",
    "pages = loader.load_and_split()\n",
    "pages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'page_content'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m text_splitter \u001b[39m=\u001b[39m RecursiveCharacterTextSplitter(\n\u001b[0;32m     11\u001b[0m     chunk_size\u001b[39m=\u001b[39mchunk_size,\n\u001b[0;32m     12\u001b[0m     chunk_overlap\u001b[39m=\u001b[39mchunk_overlap,\n\u001b[0;32m     13\u001b[0m     length_function\u001b[39m=\u001b[39mlength_function,\n\u001b[0;32m     14\u001b[0m     add_start_index\u001b[39m=\u001b[39madd_start_index\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     17\u001b[0m \u001b[39m# Split the document\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m chunks \u001b[39m=\u001b[39m text_splitter\u001b[39m.\u001b[39;49msplit_documents([pages[\u001b[39m0\u001b[39;49m]\u001b[39m.\u001b[39;49mpage_content])\n\u001b[0;32m     20\u001b[0m \u001b[39m# Access the first chunk\u001b[39;00m\n\u001b[0;32m     21\u001b[0m first_chunk \u001b[39m=\u001b[39m chunks[\u001b[39m1\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ayusi\\Envs\\new_lablab\\lib\\site-packages\\langchain\\text_splitter.py:112\u001b[0m, in \u001b[0;36mTextSplitter.split_documents\u001b[1;34m(self, documents)\u001b[0m\n\u001b[0;32m    110\u001b[0m texts, metadatas \u001b[39m=\u001b[39m [], []\n\u001b[0;32m    111\u001b[0m \u001b[39mfor\u001b[39;00m doc \u001b[39min\u001b[39;00m documents:\n\u001b[1;32m--> 112\u001b[0m     texts\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39;49mpage_content)\n\u001b[0;32m    113\u001b[0m     metadatas\u001b[39m.\u001b[39mappend(doc\u001b[39m.\u001b[39mmetadata)\n\u001b[0;32m    114\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcreate_documents(texts, metadatas\u001b[39m=\u001b[39mmetadatas)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'page_content'"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Set the desired parameters\n",
    "chunk_size = 1000\n",
    "chunk_overlap = 100\n",
    "length_function = len\n",
    "add_start_index = True\n",
    "\n",
    "# Create the text splitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=chunk_size,\n",
    "    chunk_overlap=chunk_overlap,\n",
    "    length_function=length_function,\n",
    "    add_start_index=add_start_index\n",
    ")\n",
    "\n",
    "# Split the document\n",
    "chunks = text_splitter.split_documents([pages[0].page_content])\n",
    "\n",
    "# Access the first chunk\n",
    "first_chunk = chunks[1]\n",
    "\n",
    "# Print the content of the first chunk\n",
    "print(first_chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"pdf copy\"\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "dl = DirectoryLoader(directory, \"**/*.pdf\")\n",
    "print(\"here\")\n",
    "docs = dl.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_docs = docs[:10]\n",
    "for doc in final_docs:\n",
    "    print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from IPython.core.display import Markdown\n",
    "\n",
    "# Split the loaded PDFs into smaller chunks using a text splitter\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1400, chunk_overlap=100)\n",
    "document_section = splitter.split_documents(docs)\n",
    "\n",
    "Markdown(document_section[2].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import VertexAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "embeddings = VertexAIEmbeddings()\n",
    "\n",
    "db = Chroma.from_documents(document_section, embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs = dict(k=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Create a table for the resume of Benjamin Shah?\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "\n",
    "Here is the resume of the candidate, you will be judged by how well you match this distribution.\n",
    "***\n",
    "\n",
    "{resume}\n",
    "\n",
    "***\n",
    "You will now evaluate the resume and extract key features and and then add it this table in Markdown format only , and id you cannot find some data for the respective column add None.\n",
    "\n",
    "For example: \n",
    "\n",
    "\n",
    "\n",
    "| Name | Summary | Work Experience | Years Of Experience | Skills | Projects | Education | Certifications | Awards and Achievements |\n",
    "|---|---|---|---|---|---|---|---|---|\n",
    "| John Doe | Software Engineer | 10 years | Java, Python, C++ | Google Search, Facebook Ads, Uber | Stanford University | AWS Certified Solutions Architect - Associate, Google Cloud Certified Professional Cloud Architect | Google Founders' Award, ACM Grace Hopper Award |\n",
    "| Jane Doe | Data Scientist | 5 years | Machine Learning, Statistics, SQL | Netflix Recommendation Engine, Amazon Fraud Detection | University of California, Berkeley | IBM Certified Data Scientist, Microsoft Certified Azure Data Scientist Associate | Kaggle Competition Winner, IEEE Data Science Award |\n",
    "\n",
    "\n",
    "\n",
    "You'll be evaluated on:\n",
    "- how much important data were you able to identiy\n",
    "- are these metrics required for the job posting that was posted \n",
    "- Is the output you have given is in proper Markdown format?\n",
    "\n",
    "\n",
    "\n",
    "Question : {question}\n",
    "\n",
    "\n",
    "This is the table with the details extracted from the resume: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"resume\", \"question\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "llm = VertexAI(model_name=\"text-bison@001\") # select the model\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "resume = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "question = \"Create a table for the resume of OLIVIA WILSON?\"\n",
    "Markdown(llm_chain.run(question = question, resume = resume))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
